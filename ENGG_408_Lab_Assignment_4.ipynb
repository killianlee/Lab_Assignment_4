{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 4: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this assignment, you will implement and analyze a Support Vector Machine (SVM).\n",
    "\n",
    "We've attached a dataset, `MNIST.mat`, located in `/home/jovyan/work`, containing a sample of the famous MNIST benchmark. In this lab, you will develop predictive models for this data set and write a report on your findings. You will have less guidance in this lab, as you have more experience in the programming environment and we want you to have more ownership of your work. If you have questions, please reach out early and often. \n",
    "\n",
    "\n",
    "### Roadmap\n",
    "In this lab, you will answer five questions where we:\n",
    "\n",
    "1. Train a SVM to perform binary classification with non-linear kernels.\n",
    "\n",
    "2. Implement a predictive model.\n",
    "\n",
    "3. Compare the performance of two voting schemes.\n",
    "\n",
    "4. Discuss your strategy for hyperparameter tuning.\n",
    "\n",
    "5. Generate multiclass confusion matricies for your model.\n",
    "\n",
    "### Restriction\n",
    "You are not allowed to import an SVM from, for instance, `scikit-learn`.\n",
    "You may, however, use a library (such as `scipy.optimize.minimize` or `cvxopt.solvers.qp`) for the optimization process. The code to install the `cvxopt` library is included in the first code cell, if needed. \n",
    "\n",
    "### Goals of This Lab\n",
    "The goals of this lab are to:\n",
    "\n",
    "1. Give you experience constructing and analyzing SVMs.\n",
    "\n",
    "2. Continue to hone your communication skills through a brief report.\n",
    "\n",
    "### Expectations\n",
    "All lab submissions are individual and every item you submit should be a reflection of your own work. You should have ownership over the entirety of any lab you submit in this course. While your work is your own, we understand that it can be helpful in learning machine learning to collaborate with your peers, which can range from high-level discussion of a problem to debugging. Having others look at our code encourages us to write code with readability in mind. In practice, we will never work in a silo, and being able to discuss these topics with others well is a valuable skill. When you collaborate with another student, please cite them appropriately and be respectful of sharing too much. The Academic Honor Principle applies.\n",
    "\n",
    "We respectfully ask that in the interest in furthering your own understanding of the material, that you refrain from using generative AI to code for you. Your work should be your own and you should feel comfortable justifying each design decision you make. \n",
    "\n",
    "Please cite any outside sources you reference.\n",
    "\n",
    "### Evaluation\n",
    "You will be evaluated on the quality of your code and report. Your report must provide summaries of each method's performance and some additional details of your implementation. Compare the relative strengths and weaknesses of the methods based on both the experimental results and your understanding of the algorithms.\n",
    "\n",
    "### What to Submit\n",
    "Please submit the following:\n",
    "\n",
    "1. A link to your notebook so the TAs can evaluate your code.\n",
    "\n",
    "2. A brief write-up that answers the 5 questions posed in this lab and justifies your model. Ensure that any figures you create are accessible and easy to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Installation:\n",
    "In this lab we will use the cvxopt library, whose documentation can be found here: https://cvxopt.org/userguide/index.html.\n",
    "\n",
    "We are using version 1.3.2 of cvxopt. You need only run this command once a lab session, then you may comment out the command for future runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxopt in c:\\users\\zedd\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I6DE-WKu5x0Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from cvxopt import matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Data\n",
    "You can load the data with `scipy.io.loadmat`, which will return a Python dictionary containing the test and train data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import the data\n",
    "mnist = loadmat('MNIST.mat')\n",
    "test_samples = mnist['test_samples']\n",
    "test_samples_labels = mnist['test_samples_labels']\n",
    "train_samples = mnist['train_samples']\n",
    "train_samples_labels = mnist['train_samples_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk06Xdaf8EqO"
   },
   "source": [
    "## Question 1:\n",
    "Develop code for training an SVM for binary classification with nonlinear kernels. You'll need to accomodate non-overlapping class distributions. One way to implement this is to maximize (7.32) subject to (7.33) and (7.34). It may be helpful to redefine these as matrix operations. Let ${1}\\in\\mathbb{R}^{N\\times 1}$ be the vector whose entries are all 1's. Let $\\mathbf{a}\\in\\mathbb{R}^{N\\times 1}$ have entries $a_i$. Let $\\mathbf{T}\\in\\mathbb{R}^{N\\times N}$ be a diagonal matrix with $\\mathbf{T}_{ii} = t_i$ on the diagonal. Then we can reformulate the objective to be\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& \\text{maximize}\n",
    "& & \\tilde{L}(\\mathbf{a}) = {1}^{\\mathrm{T}}\\mathbf{a} - \\frac{1}{2} \\mathbf{a}^{\\mathrm{T}} \\mathbf{T}\\mathbf{K} \\mathbf{T}\\mathbf{a} \\\\\n",
    "& \\text{subject to}\n",
    "& & {1}^{\\mathrm{T}} \\mathbf{a} \\preceq C \\\\\n",
    "& & & {1}^{\\mathrm{T}} \\mathbf{a} \\succeq 0 \\\\\n",
    "& & & \\mathbf{a}^{\\mathrm{T}} \\mathbf{t} = 0\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "The \"$\\preceq$\" symbol here means element-wise comparison. This formulation is very close to what `cvxopt` expects.\n",
    "\n",
    "Hint (`cvxopt` expects the following form):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& \\text{minimize}\n",
    "& & \\tilde{L}(\\mathbf{a}) = \\frac{1}{2} \\mathbf{a}^{\\mathrm{T}} \\mathbf{T}\\mathbf{K} \\mathbf{T}\\mathbf{a} - {1}^{\\mathrm{T}}\\mathbf{a} \\\\\n",
    "& \\text{subject to}\n",
    "& & G \\mathbf{a} \\preceq h \\\\\n",
    "& & & {\\mathbf{t}}^{\\mathrm{T}}\\mathbf{a} = 0\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "where $G$ is an $N\\times N$ identity matrix ontop of $-1$ times an $N\\times N$ identity matrix and $h \\in\\mathbb{R}^{2N}$ where the first $N$ entries are $C$ and the second $N$ enties are $0$.\n",
    "\n",
    "## Question 2:\n",
    "Develop code to predict the $\\{-1,+1\\}$ class for new data. To use the predictive model (7.13) you need to determine $b$, which can be done with (7.37)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SxWx3YK_9sBP"
   },
   "outputs": [],
   "source": [
    "def nonlinear_kernel(X, Y):\n",
    "    \"\"\"RBF kernel\"\"\"\n",
    "    gamma=0.1\n",
    "    X_norm=np.sum(X**2, axis=1)\n",
    "    Y_norm= np.sum(Y**2, axis=1)\n",
    "    K =X_norm[:, None] + Y_norm[None, :]-2 * np.dot(X, Y.T)\n",
    "    return np.exp(-gamma *K)\n",
    "\n",
    "class SVM(object):\n",
    "    ###Binary SVM classifier with nonlinear kernel support.##\n",
    "    def __init__(self, kernel=nonlinear_kernel, C=1.0):\n",
    "        self.kernel= kernel #  kernel function\n",
    "        self.C =C  #regularization parameter\n",
    "        self.a =None #lagrange multipliers\n",
    "        self.b= None  #bias\n",
    "        self.sv_X =None #support vectors\n",
    "        self.sv_y=None  #Support vector labels\n",
    "        self.sv_a= None  #support vector coefficients\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ###Train the SVM using quadratic programming.\n",
    "        y= y.astype(np.float64).flatten()\n",
    "        n_samples=X.shape[0]\n",
    "        \n",
    "        #compute kernel matrix\n",
    "        K =self.kernel(X,X)\n",
    "        K_t =np.outer(y , y)*K\n",
    "        \n",
    "        #convert to CVXOPT matrices\n",
    "        P=cvxopt.matrix(K_t)\n",
    "        q=cvxopt.matrix(-np.ones(n_samples))\n",
    "        G=cvxopt.matrix(np.vstack([np.eye(n_samples),-np.eye(n_samples)])) #np.eye, Return a 2-D array with ones on the diagonal and zeros elsewhere.\n",
    "        h=cvxopt.matrix(np.hstack([self.C*np.ones(n_samples), np.zeros(n_samples)]))\n",
    "        A=cvxopt.matrix(y.reshape(1,-1).astype(float))\n",
    "        b =cvxopt.matrix(0.0)\n",
    "        \n",
    "        #solve QP problem\n",
    "        solution=cvxopt.solvers.qp(P,q, G, h,A, b)\n",
    "        a =np.ravel(solution['x'])\n",
    "        \n",
    "        #store support vector\n",
    "        sv_mask =a >1e-5 #using 1e-5 to avoid problems with numeric limitation\n",
    "        self.sv_X=X[sv_mask]\n",
    "        self.sv_y=y[sv_mask]\n",
    "        self.sv_a=a[sv_mask]\n",
    "        \n",
    "        #compute bias term\n",
    "        margin_mask =(a> 1e-5)&(a <self.C)\n",
    "        if np.any(margin_mask):\n",
    "            K_sv =self.kernel(X,X[margin_mask])\n",
    "            self.b=np.mean(y[margin_mask] -np.dot(a*y, K_sv))\n",
    "        else:\n",
    "            K_sv =self.kernel(X,self.sv_X)\n",
    "            self.b=np.mean(self.sv_y- np.dot(self.sv_a*self.sv_y, K_sv))\n",
    "\n",
    "    def decision_function(self, X):\n",
    "       ###Compute signed distance to hyperplane.\n",
    "        K_test =self.kernel(X,self.sv_X)\n",
    "        return np.dot(K_test,self.sv_a*self.sv_y)+self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPYKRw6w9sRi"
   },
   "source": [
    "## Question 3:\n",
    "Using your implementation, compare multiclass classification performance of two different voting schemes:\n",
    "\n",
    "* one versus rest\n",
    "* one versus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_RwZj21p94bv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR Accuracy: 0.8760\n",
      "OvO Accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "class OvRClassifier:\n",
    "   ##One-vs-Rest classifier with accelerated training with sampling.##\n",
    "    def __init__(self, C=1.0, kernel=nonlinear_kernel, sample_ratio=0.2, random_state=None):\n",
    "        self.classifiers= {}\n",
    "        self.classes =None #class labels\n",
    "        self.C =C\n",
    "        self.kernel= kernel\n",
    "        self.sample_ratio=sample_ratio #partial of data to use (0.0-1.0)\n",
    "        self.random_state= random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ###Train with random subsampling.###\n",
    "        self.classes= np.unique(y)\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            #subsample training dataa\n",
    "            n_samples= int(len(X)*self.sample_ratio)\n",
    "            indices =  np.random.choice(len(X), n_samples, replace=False)\n",
    "            X_sub, y_sub =X[indices], y[indices]\n",
    "            \n",
    "            #Train binary classifier\n",
    "            y_bin=np.where(y_sub == cls, 1, -1)\n",
    "            svm=SVM(kernel=self.kernel, C=self.C)\n",
    "            svm.fit(X_sub, y_bin)\n",
    "            self.classifiers[cls] = svm\n",
    "\n",
    "    def predict(self, X):\n",
    "        ###Predict using max decision value.\n",
    "        scores=np.zeros((X.shape[0], len(self.classes)))\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            scores[:, idx] =self.classifiers[cls].decision_function(X)\n",
    "        return self.classes[np.argmax(scores, axis=1)]\n",
    "\n",
    "class OvOClassifier:\n",
    "    \"\"\"One-vs-One classifier with accelerated training with sampling.\"\"\"\n",
    "    def __init__(self, C=1.0, kernel=nonlinear_kernel, sample_ratio=0.2, random_state=None):\n",
    "        self.classifiers =[]\n",
    "        self.classes =None\n",
    "        self.C =C\n",
    "        self.kernel =kernel\n",
    "        self.sample_ratio =sample_ratio\n",
    "        self.random_state =random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train with random subsampling.\"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        #generate all classs pairs\n",
    "        n_classes = len(self.classes)\n",
    "        for i in range(n_classes):\n",
    "            for j in range(i+1, n_classes):\n",
    "                cls_i, cls_j =self.classes[i], self.classes[j]\n",
    "                \n",
    "                #get samples for current pair\n",
    "                mask =np.logical_or(y == cls_i, y == cls_j)\n",
    "                X_pair, y_pair = X[mask], y[mask]\n",
    "                \n",
    "                #subsample pair data\n",
    "                n_samples =int(len(X_pair)*self.sample_ratio)\n",
    "                if n_samples ==0: continue\n",
    "                indices = np.random.choice(len(X_pair), n_samples, replace=False)\n",
    "                X_sub, y_sub = X_pair[indices], y_pair[indices]\n",
    "                \n",
    "                ##Train binary classifier\n",
    "                y_bin = np.where(y_sub == cls_i, 1, -1)\n",
    "                svm = SVM(kernel=self.kernel, C=self.C)\n",
    "                svm.fit(X_sub, y_bin)\n",
    "                self.classifiers.append((svm, cls_i, cls_j))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using majority voting.\"\"\"\n",
    "        votes =np.zeros((X.shape[0], len(self.classes)))\n",
    "        for svm, cls_i, cls_j in self.classifiers:\n",
    "            pred =svm.predict(X)\n",
    "            for i, label in enumerate(np.where(pred == 1, cls_i, cls_j)):\n",
    "                votes[i, np.where(self.classes ==label)[0][0]] += 1\n",
    "        return self.classes[np.argmax(votes, axis=1)]\n",
    "\n",
    "X_train = mnist['train_samples']\n",
    "y_train = mnist['train_samples_labels'].ravel().astype(int)\n",
    "X_test = mnist['test_samples']\n",
    "y_test = mnist['test_samples_labels'].ravel().astype(int)\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False #turns off the screen output during calls to the solvers.\n",
    "\n",
    "# OvR with acceleration\n",
    "ovr = OvRClassifier(C=10.0,sample_ratio=0.3,random_state=42)\n",
    "ovr.fit(X_train, y_train)\n",
    "print(f\"OvR Accuracy: {np.mean(ovr.predict(X_test) ==y_test):.4f}\")\n",
    "\n",
    "#OvO with acceleration\n",
    "ovo = OvOClassifier(C=10.0, sample_ratio=0.3, random_state=42)\n",
    "ovo.fit(X_train, y_train)\n",
    "print(f\"OvO Accuracy: {np.mean(ovo.predict(X_test) ==y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68yfKC6I93Yr"
   },
   "source": [
    "## Question 4:\n",
    "The parameter $C>0$ controls the tradeoff between the size of the margin and the slack variable penalty. It is analogous to the inverse of a regularization coefficient. Include in your report a brief discussion of how you found an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XVGyehhW92yZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 10.0000, Validation Accuracy: 0.8250\n"
     ]
    }
   ],
   "source": [
    "# Hint: Try using np.logspace for hyperparameter tuning\n",
    "\n",
    "#candidate C values: [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_values = np.logspace(1, 3, 5)\n",
    "\n",
    "#Randomly sample 20% of the training data\n",
    "sample_ratio= 0.2 #adjust based on time constraints\n",
    "n_samples= int(len(X_train) * sample_ratio)\n",
    "sample_indices =np.random.choice(len(X_train), n_samples, replace=False)\n",
    "X_tune =X_train[sample_indices]\n",
    "y_tune =y_train[sample_indices]\n",
    "\n",
    "#data split\n",
    "split =int(0.8 * n_samples)  # 80% training, 20% validation\n",
    "X_train_sub, X_val =X_tune[:split], X_tune[split:]\n",
    "y_train_sub, y_val =y_tune[:split], y_tune[split:]\n",
    "\n",
    "best_C = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for C in C_values:\n",
    "    #OvR classifier with current C\n",
    "    model = OvRClassifier(C=C, kernel=nonlinear_kernel)\n",
    "    #Train on the subsampled data\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    \n",
    "    #evaluate the validation set\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_accuracy = np.mean(val_pred == y_val)\n",
    "    \n",
    "    #update best C\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_C = C\n",
    "        \n",
    "cvxopt.solvers.options['show_progress'] = False #turns off the screen output during calls to the solvers.\n",
    "\n",
    "print(f\"Best C: {best_C:.4f}, Validation Accuracy: {best_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khtnlC9y-Jeu"
   },
   "source": [
    "## Question 5:\n",
    "In addition to calculating percent accuracy, generate multiclass [confusion matrices](https://en.wikipedia.org/wiki/confusion_matrix) as part of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XyNW8AAG-UW9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OvR Confusion Matrix:\n",
      "True \\ Pred |  0    1    2    3    4    5    6    7    8    9  \n",
      "---------------------------------------------------------------\n",
      "Class 0   |  84   0    0    0    0    1    1    0    0    0  \n",
      "Class 1   |  0   122   0    0    0    0    0    0    0    0  \n",
      "Class 2   |  0    1    98   1    0    0    1    3    7    2  \n",
      "Class 3   |  0    0    2    94   0    8    3    5    0    3  \n",
      "Class 4   |  0    1    0    0    97   0    5    0    0    5  \n",
      "Class 5   |  3    0    1    5    1    74   0    4    4    0  \n",
      "Class 6   |  2    0    0    1    0    5    78   0    1    0  \n",
      "Class 7   |  0    6    3    2    3    0    0    81   0    4  \n",
      "Class 8   |  1    0    2    3    3    3    0    3    68   3  \n",
      "Class 9   |  0    1    0    1    3    2    0    3    2    80 \n",
      "\n",
      "OvO Confusion Matrix:\n",
      "True \\ Pred |  0    1    2    3    4    5    6    7    8    9  \n",
      "---------------------------------------------------------------\n",
      "Class 0   |  82   0    1    1    0    1    1    0    0    0  \n",
      "Class 1   |  0   120   0    0    0    0    0    0    2    0  \n",
      "Class 2   |  0    1    98   0    1    0    1    3    7    2  \n",
      "Class 3   |  0    0    2    90   0    13   3    4    1    2  \n",
      "Class 4   |  0    1    2    0    91   0    2    0    1    11 \n",
      "Class 5   |  1    0    1    5    1    81   0    0    3    0  \n",
      "Class 6   |  2    1    2    0    1    4    76   0    1    0  \n",
      "Class 7   |  0    1    2    0    2    0    0    89   2    3  \n",
      "Class 8   |  0    0    3    3    2    2    1    1    67   7  \n",
      "Class 9   |  0    0    0    2    1    0    0    4    1    84 \n"
     ]
    }
   ],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred, classes):\n",
    "    #y_true:ground truth labels\n",
    "    #y_pred:predicted labels\n",
    "    #classes:unique class labels\n",
    "    #cm :confusion matrix.(n_classes, n_classes)\n",
    "    n_classes =len(classes)\n",
    "    cm =np.zeros((n_classes, n_classes), dtype=int)\n",
    "    class_to_idx ={cls: idx for idx, cls in enumerate(classes)}\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_idx =class_to_idx[true]\n",
    "        pred_idx =class_to_idx[pred]\n",
    "        cm[true_idx][pred_idx] +=1\n",
    "    return cm\n",
    "\n",
    "def print_confusion_matrix(cm, classes):\n",
    "    ##Print confusion matrix.\n",
    "    header= \"True \\\\ Pred | \" + \" \".join(f\"{cls:^4}\" for cls in classes)\n",
    "    print(header)\n",
    "    print(\"-\" *len(header))\n",
    "    for i, cls in enumerate(classes):\n",
    "        row = f\"Class{cls:^4} | \" + \" \".join(f\"{count:^4}\" for count in cm[i])\n",
    "        print(row)\n",
    "\n",
    "#get class labels\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "#generate predictions\n",
    "ovr_pred= ovr.predict(X_test)\n",
    "ovo_pred =ovo.predict(X_test)\n",
    "\n",
    "#compute confusion matrices\n",
    "ovr_cm = compute_confusion_matrix(y_test, ovr_pred, classes)\n",
    "ovo_cm =compute_confusion_matrix(y_test, ovo_pred, classes)\n",
    "\n",
    "#print results\n",
    "print(\"OvR Confusion Matrix:\")\n",
    "print_confusion_matrix(ovr_cm, classes)\n",
    "print(\"\\nOvO Confusion Matrix:\")\n",
    "print_confusion_matrix(ovo_cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to Submit\n",
    "Please submit the following:\n",
    "\n",
    "1. A link to your notebook so the TAs can evaluate your code.\n",
    "\n",
    "2. A brief write-up that answers the 5 questions posed in this lab and justifies your model. Ensure that any figures you create are accessible and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6xvWK6Kjx5ZxD6WXulDDB",
   "collapsed_sections": [],
   "name": "tufts-cs135-spring2022-ps4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
